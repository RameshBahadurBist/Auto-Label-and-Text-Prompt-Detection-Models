{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d948ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "!yolo settings datasets_dir=/home/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d743281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import supervision as sv\n",
    "from inference.models.yolo_world.yolo_world import YOLOWorld\n",
    "\n",
    "# Define the folder containing your images\n",
    "image_folder = \"/home/datasets/images/\"\n",
    "\n",
    "# Load the model\n",
    "model = YOLOWorld(model_id=\"yolo_world/l\")\n",
    "classes = [\"chicken\"]\n",
    "\n",
    "# Create the bounding box annotator\n",
    "bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
    "\n",
    "# Loop through each image in the folder\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith(\".jpeg\") or filename.endswith(\".jpg\"):  # You can add other image formats here if needed\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        \n",
    "        # Read the image\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Run the inference\n",
    "        results = model.infer(image_path, text=classes, confidence=0.01)\n",
    "\n",
    "        # Inspect the results to understand its structure\n",
    "        print(\"Results:\", results)  # Print results to understand the structure\n",
    "\n",
    "        # Assuming `results` has a list-like or attribute-like structure\n",
    "        # Access the detections (This might need adjustment based on the actual structure of the results)\n",
    "        if hasattr(results, 'detections'):\n",
    "            detections = results.detections\n",
    "        else:\n",
    "            # If detections are not found as an attribute, check if results return a list\n",
    "            # e.g., If results[0] contains detections\n",
    "            detections = sv.Detections.from_inference(results[0]) if isinstance(results, list) else None\n",
    "\n",
    "        # If detections are found, proceed with annotation\n",
    "        if detections is not None:\n",
    "            # Annotate the bounding boxes on the image\n",
    "            annotated_image = bounding_box_annotator.annotate(image, detections)\n",
    "\n",
    "            # Optionally, save the annotated image\n",
    "            output_path = os.path.join(\"/home/datasets/images/\", f\"annotated_{filename}\")\n",
    "            cv2.imwrite(output_path, annotated_image)\n",
    "\n",
    "            # Display the image (optional)\n",
    "            cv2.imshow(f\"Annotated {filename}\", annotated_image)\n",
    "            cv2.waitKey(0)\n",
    "        else:\n",
    "            print(f\"No detections found for {filename}\")\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b54ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "\n",
    "# Ensure Jupyter Notebook prints outputs immediately\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# === Setup ===\n",
    "\n",
    "# Configuration\n",
    "IMAGE_FOLDER = \"/home/datasets/images/\"  # Input folder containing images\n",
    "OUTPUT_FOLDER = \"/home/datasets/YOLOWorld/\"  # Output folder for predictions and YOLO labels\n",
    "YOLO_LABELS = [\"\", \"\"]  # Object classes to detect\n",
    "EMBEDDING_PATH = \"embeddings/custom_embeddings.npy\"  # Path to embeddings\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# Helper function to preprocess images\n",
    "def preprocess_image(image_path, transform):\n",
    "    \"\"\"Load and preprocess an image.\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "    return input_tensor\n",
    "\n",
    "# Helper function to save YOLO format labels\n",
    "def save_yolo_labels(predictions, class_ids, confidences, image_width, image_height, label_output_path):\n",
    "    \"\"\"Save predictions in YOLO format.\"\"\"\n",
    "    with open(label_output_path, \"w\") as f:\n",
    "        for box, class_id, confidence in zip(predictions, class_ids, confidences):\n",
    "            # YOLO format: class_id x_center y_center width height (normalized)\n",
    "            x_center = (box[0] + box[2]) / 2 / image_width\n",
    "            y_center = (box[1] + box[3]) / 2 / image_height\n",
    "            width = (box[2] - box[0]) / image_width\n",
    "            height = (box[3] - box[1]) / image_height\n",
    "            f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "\n",
    "# === Install YOLOWorld (Optional) ===\n",
    "!git clone --recursive https://github.com/AILab-CVC/YOLO-World.git\n",
    "!pip install -r YOLO-World/requirements.txt\n",
    "!pip install -e YOLO-World\n",
    "\n",
    "# Add YOLOWorld to the Python path\n",
    "import sys\n",
    "sys.path.append('/path/to/YOLO-World')\n",
    "\n",
    "# === Load YOLOWorld Model ===\n",
    "from yoloworld.models.simple_yolo import SimpleYOLOWorldDetector\n",
    "from clip import clip\n",
    "\n",
    "# Step 1: Generate embeddings\n",
    "if not os.path.exists(EMBEDDING_PATH):\n",
    "    print(\"Generating embeddings...\")\n",
    "    model_clip, preprocess_clip = clip.load(\"ViT-B/32\")\n",
    "    text_tokens = clip.tokenize(YOLO_LABELS)\n",
    "    with torch.no_grad():\n",
    "        text_features = model_clip.encode_text(text_tokens)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "    os.makedirs(os.path.dirname(EMBEDDING_PATH), exist_ok=True)\n",
    "    torch.save(text_features.cpu().numpy(), EMBEDDING_PATH)\n",
    "\n",
    "# Step 2: Initialize YOLOWorld\n",
    "print(\"Loading YOLOWorld model...\")\n",
    "model = SimpleYOLOWorldDetector(\n",
    "    mm_neck=True,\n",
    "    num_train_classes=len(YOLO_LABELS),\n",
    "    num_test_classes=len(YOLO_LABELS),\n",
    "    embedding_path=EMBEDDING_PATH,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "# Step 3: Define transformation for input images\n",
    "transform = Compose([Resize((640, 640)), ToTensor()])\n",
    "\n",
    "# === Detection Loop ===\n",
    "print(\"Processing images...\")\n",
    "for image_name in os.listdir(IMAGE_FOLDER):\n",
    "    if image_name.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "        # File paths\n",
    "        image_path = os.path.join(IMAGE_FOLDER, image_name)\n",
    "        label_output_path = os.path.join(OUTPUT_FOLDER, f\"{os.path.splitext(image_name)[0]}.txt\")\n",
    "\n",
    "        # Preprocess the image\n",
    "        input_tensor = preprocess_image(image_path, transform)\n",
    "\n",
    "        # Predict bounding boxes and classes\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_tensor)\n",
    "\n",
    "        # Parse model outputs (mock example: adjust for actual output format)\n",
    "        predictions = outputs[\"boxes\"]  # Bounding boxes\n",
    "        class_ids = outputs[\"labels\"]  # Class IDs\n",
    "        confidences = outputs[\"scores\"]  # Confidence scores\n",
    "\n",
    "        # Save YOLO format labels\n",
    "        save_yolo_labels(predictions, class_ids, confidences, 640, 640, label_output_path)\n",
    "        print(f\"Processed {image_name}, labels saved to {label_output_path}\")\n",
    "\n",
    "print(\"Processing complete. Outputs saved to:\", OUTPUT_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e454c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Initialize the YOLO model\n",
    "model = YOLO(\"/home/weights/best.pt\")\n",
    "\n",
    "# Define custom classes\n",
    "model.set_classes([\"Feeding\", \"Foraging\"])\n",
    "\n",
    "# Input and output directories\n",
    "image_dir = \"/home/images/test\"\n",
    "output_image_dir = \"/home/Outputimages/\"\n",
    "output_labels_dir = \"/home/Outputlabels/\"\n",
    "\n",
    "# Make sure the output directories exist\n",
    "os.makedirs(output_image_dir, exist_ok=True)\n",
    "os.makedirs(output_labels_dir, exist_ok=True)\n",
    "\n",
    "# Execute prediction for specified categories on an image\n",
    "results = model.predict(image_dir)\n",
    "\n",
    "# Process the results and save the labeled images and YOLO .txt files\n",
    "for i, result in enumerate(results):\n",
    "    # Process each image\n",
    "    img_path = result.path\n",
    "    img_name = os.path.basename(img_path)\n",
    "    image = Image.open(img_path).convert(\"RGB\")  # Open the image in RGB format\n",
    "    \n",
    "    # Draw bounding boxes on the image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # List to hold YOLO formatted labels\n",
    "    yolo_labels = []\n",
    "    \n",
    "    # Loop through the detections for this image\n",
    "    for box, cls, conf in zip(result.boxes.xyxy, result.boxes.cls, result.boxes.conf):\n",
    "        # Extract bounding box coordinates and class information\n",
    "        x1, y1, x2, y2 = box\n",
    "        class_id = int(cls)\n",
    "        confidence = conf.item()\n",
    "        class_name = model.names[class_id]\n",
    "        \n",
    "        # Draw the bounding box and class label on the image\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=\"blue\", width=3)\n",
    "        draw.text((x1, y1 - 10), f\"{class_name}: {confidence:.2f}\", fill=\"blue\")\n",
    "\n",
    "        # Convert the bounding box to YOLO format: <class_id> <x_center> <y_center> <width> <height>\n",
    "        x_center = (x1 + x2) / 2 / image.width\n",
    "        y_center = (y1 + y2) / 2 / image.height\n",
    "        width = (x2 - x1) / image.width\n",
    "        height = (y2 - y1) / image.height\n",
    "        \n",
    "        # Append YOLO label (class_id, x_center, y_center, width, height)\n",
    "        yolo_labels.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
    "\n",
    "    # Save the output image with bounding boxes\n",
    "    output_image_path = os.path.join(output_image_dir, f\"labeled_{img_name}\")\n",
    "    image.save(output_image_path)\n",
    "\n",
    "    # Save YOLO-format labels to text file\n",
    "    output_label_path = os.path.join(output_labels_dir, f\"{os.path.splitext(img_name)[0]}.txt\")\n",
    "    with open(output_label_path, 'w') as label_file:\n",
    "        for label in yolo_labels:\n",
    "            label_file.write(label + \"\\n\")\n",
    "    \n",
    "    print(f\"Processed {img_name} - Saved labeled image and YOLO labels.\")\n",
    "\n",
    "print(\"Processing complete. All labeled images and YOLO labels have been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d37130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Initialize the YOLO model\n",
    "model = YOLO(\"/home/weights/best.pt\")\n",
    "\n",
    "# Define custom classes\n",
    "model.set_classes([\"Feeding\", \"Foraging\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"])\n",
    "\n",
    "# Input and output directories\n",
    "image_dir = \"/home/images/\"\n",
    "output_image_dir = \"/home/Outputimages2/\"\n",
    "output_labels_dir = \"/home/Outputlabels2/\"\n",
    "\n",
    "# Make sure the output directories exist\n",
    "os.makedirs(output_image_dir, exist_ok=True)\n",
    "os.makedirs(output_labels_dir, exist_ok=True)\n",
    "\n",
    "# Define class colors\n",
    "class_colors = {\n",
    "    \"Dustbathing\": (255, 0, 0),    # Red for Feeding\n",
    "    \"Drinking\": (0, 0, 255),   # Blue for Foraging\n",
    "    \"Perching\": (0, 255, 0\n",
    "}\n",
    "\n",
    "# Load the Times New Roman font with size 24\n",
    "font_path = \"/home/rbist/ttf/Times_New_Roman.ttf\"  # Adjust the path if needed\n",
    "font = ImageFont.truetype(font_path, 24)  # Font size 24\n",
    "\n",
    "# Execute prediction for specified categories on an image\n",
    "results = model.predict(image_dir)\n",
    "\n",
    "# Process the results and save the labeled images and YOLO .txt files\n",
    "for i, result in enumerate(results):\n",
    "    # Process each image\n",
    "    img_path = result.path\n",
    "    img_name = os.path.basename(img_path)\n",
    "    image = Image.open(img_path).convert(\"RGB\")  # Open the image in RGB format\n",
    "    \n",
    "    # Draw bounding boxes on the image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # List to hold YOLO formatted labels\n",
    "    yolo_labels = []\n",
    "    \n",
    "    # Loop through the detections for this image\n",
    "    for box, cls, conf in zip(result.boxes.xyxy, result.boxes.cls, result.boxes.conf):\n",
    "        # Extract bounding box coordinates and class information\n",
    "        x1, y1, x2, y2 = box\n",
    "        class_id = int(cls)\n",
    "        confidence = conf.item()\n",
    "        class_name = model.names[class_id]\n",
    "        \n",
    "        # Get color for the class\n",
    "        class_color = class_colors.get(class_name, (255, 255, 255))  # Default to white if class not found\n",
    "        \n",
    "        # Draw the bounding box\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=class_color, width=3)\n",
    "\n",
    "        # Calculate text and its size\n",
    "        text = f\"{class_name}: {confidence:.2f}\"\n",
    "        \n",
    "        # Using textbbox to get the bounding box of the text\n",
    "        text_bbox = draw.textbbox((x1, y1), text, font=font)\n",
    "        text_width = text_bbox[2] - text_bbox[0]\n",
    "        text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "        # Position the text just above the bounding box, aligned to the right\n",
    "        text_x = x2 - text_width  # Align text to the right edge of the bounding box\n",
    "        text_y = y1 - text_height - 5  # Position the text just above the bounding box\n",
    "\n",
    "        # Draw the text on the image\n",
    "        draw.text((text_x, text_y), text, fill=class_color, font=font)\n",
    "\n",
    "        # Convert the bounding box to YOLO format: <class_id> <x_center> <y_center> <width> <height>\n",
    "        x_center = (x1 + x2) / 2 / image.width\n",
    "        y_center = (y1 + y2) / 2 / image.height\n",
    "        width = (x2 - x1) / image.width\n",
    "        height = (y2 - y1) / image.height\n",
    "        \n",
    "        # Append YOLO label (class_id, x_center, y_center, width, height)\n",
    "        yolo_labels.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
    "\n",
    "    # Save the output image with bounding boxes\n",
    "    output_image_path = os.path.join(output_image_dir, f\"labeled_{img_name}\")\n",
    "    image.save(output_image_path)\n",
    "\n",
    "    # Save YOLO-format labels to text file\n",
    "    output_label_path = os.path.join(output_labels_dir, f\"{os.path.splitext(img_name)[0]}.txt\")\n",
    "    with open(output_label_path, 'w') as label_file:\n",
    "        for label in yolo_labels:\n",
    "            label_file.write(label + \"\\n\")\n",
    "    \n",
    "    print(f\"Processed {img_name} - Saved labeled image and YOLO labels.\")\n",
    "\n",
    "print(\"Processing complete. All labeled images and YOLO labels have been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc041554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video Based detection\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the YOLO model\n",
    "model = YOLO(\"/home/weights/best.pt\")\n",
    "\n",
    "# Define the 11 standard attractive colors for the behaviors\n",
    "standard_colors = [\n",
    "    (255, 0, 0),      # Red\n",
    "    (0, 0, 255),      # Blue\n",
    "    (0, 255, 0),      # Green\n",
    "    (255, 165, 0),    # Orange\n",
    "    (128, 0, 128),    # Purple\n",
    "    (255, 255, 0),    # Yellow\n",
    "    (0, 255, 255),    # Cyan\n",
    "    (255, 0, 255),    # Magenta\n",
    "    (0, 0, 139),      # Dark Blue\n",
    "    (0, 255, 0),      # Lime\n",
    "    (0, 128, 128),    # Teal\n",
    "]\n",
    "\n",
    "# Define behavior classes and their corresponding colors\n",
    "behavior_class_colors = {\n",
    "    \"Feeding\": standard_colors[0],\n",
    "    \"Foraging\": standard_colors[1],\n",
    "    \"\": standard_colors[2],\n",
    "    \"\": standard_colors[3],\n",
    "    \"\": standard_colors[4],\n",
    "    \"\": standard_colors[5],\n",
    "    \"\": standard_colors[6],\n",
    "    \"\": standard_colors[7],\n",
    "    \"\": standard_colors[8],\n",
    "    \"\": standard_colors[9],\n",
    "    \"\": standard_colors[10],\n",
    "}\n",
    "\n",
    "# Load the Times New Roman font with size 24\n",
    "font_path = \"/home/ttf/Times_New_Roman.ttf\"  # Adjust the path if needed\n",
    "font = ImageFont.truetype(font_path, 24)  # Font size 24\n",
    "\n",
    "# Define a function to filter the results based on the text prompt\n",
    "def filter_classes_by_prompt(prompt):\n",
    "    available_classes = [\n",
    "        \"Feeding\", \"Foraging\", \"\", \"\", \"\", \n",
    "        \"\", \"\", \"\", \"\", \"\", \"\"\n",
    "    ]\n",
    "    # Return a list of behaviors that match the user's prompt (case-insensitive)\n",
    "    return [cls for cls in available_classes if prompt.lower() in cls.lower()]\n",
    "\n",
    "# Example: prompt can be any string, like \"Feeding\" or \"Dustbathing\"\n",
    "prompt = \"\"  # Replace with the behavior you want to detect\n",
    "\n",
    "# Filter out behaviors that match the prompt\n",
    "filtered_classes = filter_classes_by_prompt(prompt)\n",
    "\n",
    "# Input video path and output video path\n",
    "input_video_path = \"/home/videos/test_video.mp4\"\n",
    "output_video_path = \"/home/OutputVideo.avi\"\n",
    "\n",
    "# Open the input video\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# Get the video properties (frame width, height, and frames per second)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Create a VideoWriter object to save the processed video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to a PIL image\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Draw bounding boxes on the image\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "    \n",
    "    # List to hold YOLO formatted labels\n",
    "    yolo_labels = []\n",
    "    \n",
    "    # Run YOLO model on the frame (which is a PIL image)\n",
    "    results = model(pil_image)\n",
    "    \n",
    "    for result in results:\n",
    "        for box, cls, conf in zip(result.boxes.xyxy, result.boxes.cls, result.boxes.conf):\n",
    "            # Extract bounding box coordinates and class information\n",
    "            x1, y1, x2, y2 = box\n",
    "            class_id = int(cls)\n",
    "            confidence = conf.item()\n",
    "            class_name = model.names[class_id]\n",
    "            \n",
    "            # Only process detections for filtered classes\n",
    "            if class_name not in filtered_classes:\n",
    "                continue\n",
    "            \n",
    "            # Get color for the class\n",
    "            class_color = behavior_class_colors.get(class_name, (255, 255, 255))  # Default to white if class not found\n",
    "            \n",
    "            # Draw the bounding box\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=class_color, width=3)\n",
    "\n",
    "            # Calculate text and its size\n",
    "            text = f\"{class_name}: {confidence:.2f}\"\n",
    "            \n",
    "            # Using textbbox to get the bounding box of the text\n",
    "            text_bbox = draw.textbbox((x1, y1), text, font=font)\n",
    "            text_width = text_bbox[2] - text_bbox[0]\n",
    "            text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "            # Position the text just above the bounding box, aligned to the right\n",
    "            text_x = x2 - text_width  # Align text to the right edge of the bounding box\n",
    "            text_y = y1 - text_height - 5  # Position the text just above the bounding box\n",
    "\n",
    "            # Draw the text on the image\n",
    "            draw.text((text_x, text_y), text, fill=class_color, font=font)\n",
    "    \n",
    "    # Convert the PIL image back to a frame (OpenCV format)\n",
    "    frame_with_boxes = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Write the frame to the output video\n",
    "    out.write(frame_with_boxes)\n",
    "\n",
    "# Release the video capture and writer objects\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(\"Processing complete. The video with bounding boxes has been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972bc909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the YOLO model\n",
    "model = YOLO(\"/home/weights/best.pt\")\n",
    "\n",
    "# Define the 11 standard attractive colors for the behaviors\n",
    "standard_colors = [\n",
    "    (255, 0, 0), (0, 0, 255), (0, 255, 0), (255, 165, 0), \n",
    "    (128, 0, 128), (255, 255, 0), (0, 255, 255), (255, 0, 255), \n",
    "    (0, 0, 139), (0, 255, 0), (0, 128, 128)\n",
    "]\n",
    "\n",
    "# Define behavior classes and their corresponding colors\n",
    "behavior_class_colors = {\n",
    "    \"Feeding\": standard_colors[0],\n",
    "    \"Foraging\": standard_colors[1],\n",
    "    \"\": standard_colors[2],\n",
    "    \"\": standard_colors[3],\n",
    "    \"\": standard_colors[4],\n",
    "    \"\": standard_colors[5],\n",
    "    \"\": standard_colors[6],\n",
    "    \"\": standard_colors[7],\n",
    "    \"\": standard_colors[8],\n",
    "    \"\": standard_colors[9],\n",
    "    \"\": standard_colors[10],\n",
    "}\n",
    "\n",
    "# Load the font for labeling\n",
    "font_path = \"/home/ttf/Times_New_Roman.ttf\"\n",
    "font = ImageFont.truetype(font_path, 24)\n",
    "\n",
    "# Function to filter classes by text prompt\n",
    "def filter_classes_by_prompt(prompt):\n",
    "    available_classes = [\n",
    "        \"Feeding\", \"Foraging\", \"\", \"\", \"\", \n",
    "        \"\", \"\", \"\", \"\", \"\", \"\"\n",
    "    ]\n",
    "    if isinstance(prompt, str):\n",
    "        prompt = [prompt]\n",
    "    return [cls for cls in available_classes if any(p.lower() in cls.lower() for p in prompt)]\n",
    "\n",
    "# Set the text prompt\n",
    "prompt = [\"Perching\"]\n",
    "filtered_classes = filter_classes_by_prompt(prompt)\n",
    "\n",
    "# Open the video file or webcam stream\n",
    "video_path = \"/home/BH.mp4\"  # Replace with your video path or 0 for webcam\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Set up matplotlib for inline video display\n",
    "plt.ion()  # Turn interactive mode on\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.axis('off')  # Hide axes\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert frame to RGB\n",
    "        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Run YOLO model on the frame\n",
    "        results = model.predict(frame)\n",
    "\n",
    "        # Draw detections on the frame\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        for box, cls, conf in zip(results[0].boxes.xyxy, results[0].boxes.cls, results[0].boxes.conf):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            class_id = int(cls)\n",
    "            confidence = conf.item()\n",
    "            class_name = model.names[class_id]\n",
    "\n",
    "            # Filter detections based on the prompt\n",
    "            if class_name not in filtered_classes:\n",
    "                continue\n",
    "\n",
    "            # Draw bounding box\n",
    "            color = behavior_class_colors.get(class_name, (255, 255, 255))\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=color, width=3)\n",
    "\n",
    "            # Add label\n",
    "            label = f\"{class_name} {confidence:.2f}\"\n",
    "            text_bbox = draw.textbbox((x1, y1), label, font=font)\n",
    "            text_x, text_y = text_bbox[:2]\n",
    "            draw.text((text_x, text_y - 10), label, fill=color, font=font)\n",
    "\n",
    "        # Convert PIL image back to OpenCV format for display\n",
    "        frame_rgb = np.array(image)\n",
    "\n",
    "        # Display the frame using matplotlib\n",
    "        ax.imshow(frame_rgb)\n",
    "        plt.draw()  # Update the figure with the new frame\n",
    "        plt.pause(0.01)  # Pause for 10ms to update the figure\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped by user.\")\n",
    "\n",
    "finally:\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    plt.ioff()  # Turn off interactive mode\n",
    "    plt.show()  # Show the final figure after the loop finishes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48a75fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image based detection\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Initialize the YOLO model\n",
    "model = YOLO(\"/home/weights/best.pt\")\n",
    "\n",
    "# Define the 11 standard attractive colors for the behaviors\n",
    "standard_colors = [\n",
    "    (255, 0, 0),      # Red\n",
    "    (0, 0, 255),      # Blue\n",
    "    (0, 255, 0),      # Green\n",
    "    (255, 165, 0),    # Orange\n",
    "    (128, 0, 128),    # Purple\n",
    "    (255, 255, 0),    # Yellow\n",
    "    (0, 255, 255),    # Cyan\n",
    "    (255, 0, 255),    # Magenta\n",
    "    (0, 0, 139),      # Dark Blue\n",
    "    (0, 255, 0),      # Lime\n",
    "    (0, 128, 128),    # Teal\n",
    "]\n",
    "\n",
    "# Define behavior classes and their corresponding colors\n",
    "behavior_class_colors = {\n",
    "    \"Feeding\": standard_colors[0],\n",
    "    \"Foraging\": standard_colors[1],\n",
    "    \"\": standard_colors[2],\n",
    "    \"\": standard_colors[3],\n",
    "    \"\": standard_colors[4],\n",
    "    \"\": standard_colors[5],\n",
    "    \"\": standard_colors[6],\n",
    "    \"\": standard_colors[7],\n",
    "    \"\": standard_colors[8],\n",
    "    \"\": standard_colors[9],\n",
    "    \"\": standard_colors[10],\n",
    "}\n",
    "\n",
    "# Input and output directories\n",
    "image_dir = \"/home/images/\"\n",
    "output_image_dir = \"/home/Predictedimages1/\"\n",
    "output_labels_dir = \"/home/Predictedlabels1/\"\n",
    "\n",
    "# Make sure the output directories exist\n",
    "os.makedirs(output_image_dir, exist_ok=True)\n",
    "os.makedirs(output_labels_dir, exist_ok=True)\n",
    "\n",
    "# Load the Times New Roman font with size 24\n",
    "font_path = \"/home/ttf/Times_New_Roman.ttf\"  # Adjust the path if needed\n",
    "font = ImageFont.truetype(font_path, 24)  # Font size 24\n",
    "\n",
    "# Define a function to filter the results based on the text prompt\n",
    "def filter_classes_by_prompt(prompt):\n",
    "    available_classes = [\n",
    "        \"Feeding\", \"Foraging\", \"\", \"\", \"\", \n",
    "        \"\", \"\", \"\", \"\", \"\", \"\"\n",
    "    ]\n",
    "    # Return a list of behaviors that match the user's prompt (case-insensitive)\n",
    "    # Prompt can be a string or a list of strings\n",
    "    if isinstance(prompt, str):\n",
    "        prompt = [prompt]\n",
    "    \n",
    "    return [cls for cls in available_classes if any(p.lower() in cls.lower() for p in prompt)]\n",
    "\n",
    "# Example: prompt can be a single string or a list of strings\n",
    "prompt = [\"Feeding\", \"Foraging\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]  # Replace with the behaviors you want to detect\n",
    "\n",
    "# Filter out behaviors that match the prompt\n",
    "filtered_classes = filter_classes_by_prompt(prompt)\n",
    "\n",
    "# Execute prediction for specified categories on an image\n",
    "results = model.predict(image_dir)\n",
    "\n",
    "# Process the results and save the labeled images and YOLO .txt files\n",
    "for i, result in enumerate(results):\n",
    "    # Process each image\n",
    "    img_path = result.path\n",
    "    img_name = os.path.basename(img_path)\n",
    "    image = Image.open(img_path).convert(\"RGB\")  # Open the image in RGB format\n",
    "    \n",
    "    # Draw bounding boxes on the image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # List to hold YOLO formatted labels\n",
    "    yolo_labels = []\n",
    "    \n",
    "    # Loop through the detections for this image\n",
    "    for box, cls, conf in zip(result.boxes.xyxy, result.boxes.cls, result.boxes.conf):\n",
    "        # Extract bounding box coordinates and class information\n",
    "        x1, y1, x2, y2 = box\n",
    "        class_id = int(cls)\n",
    "        confidence = conf.item()\n",
    "        class_name = model.names[class_id]\n",
    "        \n",
    "        # Only process detections for filtered classes\n",
    "        if class_name not in filtered_classes:\n",
    "            continue\n",
    "        \n",
    "        # Get color for the class\n",
    "        class_color = behavior_class_colors.get(class_name, (255, 255, 255))  # Default to white if class not found\n",
    "        \n",
    "        # Draw the bounding box\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=class_color, width=3)\n",
    "\n",
    "        # Calculate text and its size\n",
    "        text = f\"{class_name}: {confidence:.2f}\"\n",
    "        \n",
    "        # Using textbbox to get the bounding box of the text\n",
    "        text_bbox = draw.textbbox((x1, y1), text, font=font)\n",
    "        text_width = text_bbox[2] - text_bbox[0]\n",
    "        text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "        # Position the text just above the bounding box, aligned to the right\n",
    "        text_x = x2 - text_width  # Align text to the right edge of the bounding box\n",
    "        text_y = y1 - text_height - 5  # Position the text just above the bounding box\n",
    "\n",
    "        # Draw the text on the image\n",
    "        draw.text((text_x, text_y), text, fill=class_color, font=font)\n",
    "\n",
    "        # Convert the bounding box to YOLO format: <class_id> <x_center> <y_center> <width> <height>\n",
    "        x_center = (x1 + x2) / 2 / image.width\n",
    "        y_center = (y1 + y2) / 2 / image.height\n",
    "        width = (x2 - x1) / image.width\n",
    "        height = (y2 - y1) / image.height\n",
    "        \n",
    "        # Append YOLO label (class_id, x_center, y_center, width, height)\n",
    "        yolo_labels.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
    "\n",
    "    # Save the output image with bounding boxes\n",
    "    output_image_path = os.path.join(output_image_dir, f\"labeled_{img_name}\")\n",
    "    image.save(output_image_path)\n",
    "\n",
    "    # Save YOLO-format labels to text file\n",
    "    output_label_path = os.path.join(output_labels_dir, f\"{os.path.splitext(img_name)[0]}.txt\")\n",
    "    with open(output_label_path, 'w') as label_file:\n",
    "        for label in yolo_labels:\n",
    "            label_file.write(label + \"\\n\")\n",
    "    \n",
    "    print(f\"Processed {img_name} - Saved labeled image and YOLO labels.\")\n",
    "\n",
    "print(\"Processing complete. All labeled images and YOLO labels have been saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d7a43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image-based behavior detection using YOLO with confidence filtering\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(\"/home/weights/best.pt\")\n",
    "\n",
    "# Define 11 standard colors for different behaviors\n",
    "standard_colors = [\n",
    "    (255, 0, 0),      # Red\n",
    "    (0, 0, 255),      # Blue\n",
    "    (0, 255, 0),      # Green\n",
    "    (255, 165, 0),    # Orange\n",
    "    (128, 0, 128),    # Purple\n",
    "    (255, 255, 0),    # Yellow\n",
    "    (0, 255, 255),    # Cyan\n",
    "    (255, 0, 255),    # Magenta\n",
    "    (0, 0, 139),      # Dark Blue\n",
    "    (0, 255, 0),      # Lime\n",
    "    (0, 128, 128),    # Teal\n",
    "]\n",
    "\n",
    "# Mapping of class names to colors\n",
    "behavior_class_colors = {\n",
    "    \"Feeding\": standard_colors[0],\n",
    "    \"Foraging\": standard_colors[1],\n",
    "    \"\": standard_colors[2],\n",
    "    \"\": standard_colors[3],\n",
    "    \"\": standard_colors[4],\n",
    "    \"\": standard_colors[5],\n",
    "    \"\": standard_colors[6],\n",
    "    \"\": standard_colors[7],\n",
    "    \"\": standard_colors[8],\n",
    "    \"\": standard_colors[9],\n",
    "    \"\": standard_colors[10],\n",
    "}\n",
    "\n",
    "# Directories\n",
    "image_dir = \"/home/images/\"\n",
    "output_image_dir = \"/home/Predictedimages2/\"\n",
    "output_labels_dir = \"/home/Predictedlabels2/\"\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(output_image_dir, exist_ok=True)\n",
    "os.makedirs(output_labels_dir, exist_ok=True)\n",
    "\n",
    "# Load font\n",
    "font_path = \"/home/rbist/ttf/Times_New_Roman.ttf\"\n",
    "font = ImageFont.truetype(font_path, 24)\n",
    "\n",
    "# Filter prompt\n",
    "def filter_classes_by_prompt(prompt):\n",
    "    all_classes = list(behavior_class_colors.keys())\n",
    "    if isinstance(prompt, str):\n",
    "        prompt = [prompt]\n",
    "    return [cls for cls in all_classes if any(p.lower() in cls.lower() for p in prompt)]\n",
    "\n",
    "# Behavior prompt: choose what you want to detect\n",
    "prompt = [\"Feeding\", \"Foraging\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]\n",
    "filtered_classes = filter_classes_by_prompt(prompt)\n",
    "\n",
    "# Run inference with confidence threshold of 0.5\n",
    "results = model.predict(source=image_dir, conf=0.5)\n",
    "\n",
    "# Process each image result\n",
    "for result in results:\n",
    "    img_path = result.path\n",
    "    img_name = os.path.basename(img_path)\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    yolo_labels = []\n",
    "\n",
    "    for box, cls, conf in zip(result.boxes.xyxy, result.boxes.cls, result.boxes.conf):\n",
    "        x1, y1, x2, y2 = box\n",
    "        class_id = int(cls)\n",
    "        confidence = conf.item()\n",
    "        class_name = model.names[class_id]\n",
    "\n",
    "        # Filter only desired behaviors\n",
    "        if class_name not in filtered_classes:\n",
    "            continue\n",
    "\n",
    "        color = behavior_class_colors.get(class_name, (255, 255, 255))\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=color, width=3)\n",
    "\n",
    "        # Label text\n",
    "        text = f\"{class_name}: {confidence:.2f}\"\n",
    "        text_bbox = draw.textbbox((x1, y1), text, font=font)\n",
    "        text_width = text_bbox[2] - text_bbox[0]\n",
    "        text_height = text_bbox[3] - text_bbox[1]\n",
    "        text_x = x2 - text_width\n",
    "        text_y = y1 - text_height - 5\n",
    "        draw.text((text_x, text_y), text, fill=color, font=font)\n",
    "\n",
    "        # Convert to YOLO format\n",
    "        x_center = (x1 + x2) / 2 / image.width\n",
    "        y_center = (y1 + y2) / 2 / image.height\n",
    "        width = (x2 - x1) / image.width\n",
    "        height = (y2 - y1) / image.height\n",
    "        yolo_labels.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
    "\n",
    "    # Save labeled image\n",
    "    image.save(os.path.join(output_image_dir, f\"labeled_{img_name}\"))\n",
    "\n",
    "    # Save YOLO label\n",
    "    label_file_path = os.path.join(output_labels_dir, f\"{os.path.splitext(img_name)[0]}.txt\")\n",
    "    with open(label_file_path, 'w') as f:\n",
    "        for label in yolo_labels:\n",
    "            f.write(label + \"\\n\")\n",
    "\n",
    "    print(f\"✅ Processed {img_name} — labels and image saved.\")\n",
    "\n",
    "print(\"\\n🎉 Done! All images processed with confidence ≥ 0.50.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
