{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ee32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Broiler and Hen\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from groundingdino.util.inference import Model, annotate\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import supervision as sv\n",
    "\n",
    "# Paths to models and images\n",
    "GROUNDING_DINO_CONFIG = \"groundingdino/config/GroundingDINO_SwinB_cfg.py\"  #can use SwinB and SwinT\n",
    "GROUNDING_DINO_CHECKPOINT = \"weights/groundingdino_swinb_cogcoor.pth\"\n",
    "\n",
    "DATASET_NAME = \"\"\n",
    "\n",
    "DATASET_DIR = f\"datasets/{DATASET_NAME}\"\n",
    "IMAGE_INPUT = f\"datasets/{DATASET_NAME}/images/val\"\n",
    "LABELS_OUTPUT_DIR = f\"datasets/{DATASET_NAME}/labels/val2\"\n",
    "ANNOTATED_IMG_OUTPUT = f\"datasets/{DATASET_NAME}/out_val\"\n",
    "YOLO_TRAIN_DATA_PATH = \"datasets/broiler/data.yaml\"\n",
    "YOLO_TEST_PATH = f\"datasets/{DATASET_NAME}/images/test/\"\n",
    "\n",
    "\n",
    "# change for apple macbook\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "\n",
    "# Initialize Grounding DINO\n",
    "grounding_dino_model = Model(GROUNDING_DINO_CONFIG, GROUNDING_DINO_CHECKPOINT, device)\n",
    "\n",
    "# Define the classes or queries for Grounding DINO\n",
    "queries = [\"\"]  # Example queries\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(LABELS_OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(ANNOTATED_IMG_OUTPUT, exist_ok=True)\n",
    "\n",
    "\n",
    "box_annotator = sv.BoxAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
    "label_annotator = sv.LabelAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
    "\n",
    "def filter_detection_by_area (detections: sv.Detections):\n",
    "    mean_h = np.mean([y2-y1 for _, y1 , _, y2 in detections.xyxy])\n",
    "    mean_w = np.mean([x2-x1 for x1, _ , x2, _ in detections.xyxy])\n",
    "\n",
    "    std_h = np.std([y2-y1 for _, y1 , _, y2 in detections.xyxy])\n",
    "    std_w = np.std([x2-x1 for x1, _ , x2, _ in detections.xyxy])\n",
    "\n",
    "    area_indices = []\n",
    "    for _xyxy, _, _, _, _, _ in detections:\n",
    "        x1, y1, x2, y2 = _xyxy\n",
    "        val = False if (x2-x1 >= mean_w + std_w ) or (y2-y1 > mean_h + std_h)  else True\n",
    "        area_indices.append(val)\n",
    "    return detections[area_indices]\n",
    "\n",
    "images_map = {}\n",
    "detections_map = {}\n",
    "# # Process each image\n",
    "progress_bar = tqdm(os.listdir(IMAGE_INPUT), desc=\"Labeling images\")\n",
    "for image_name in progress_bar:\n",
    "    progress_bar.set_description(desc=f\"Labeling {image_name}\", refresh=True)\n",
    "    image_path = os.path.join(IMAGE_INPUT, image_name)\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    images_map[image_name] = image.copy()\n",
    "\n",
    "    detections = grounding_dino_model.predict_with_classes(\n",
    "        image=image,\n",
    "        classes=queries,\n",
    "        box_threshold=0.13,\n",
    "        text_threshold=0.2,\n",
    "    )\n",
    "        \n",
    "    detections = detections.with_nms(threshold=1)   #chance a confidence interval to remove multiple boxes.\n",
    "    detections.class_id = np.zeros(len(detections.xyxy))\n",
    "    detections = filter_detection_by_area(detections)\n",
    "    detections_map[image_name] = detections\n",
    "\n",
    "    labels = [f\"{queries[int(class_id)]} {confidence:0.2f}\" for _, _, confidence, class_id, _, _ in detections]\n",
    "    annotated_frame = cv2.cvtColor(image.copy(), cv2.COLOR_RGB2BGR)\n",
    "    annotated_image = box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "    annotated_image = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)\n",
    "    cv2.imwrite(ANNOTATED_IMG_OUTPUT + \"/\" + image_name, annotated_image)\n",
    "            \n",
    "dataset = sv.DetectionDataset(\n",
    "    queries, images_map, detections_map\n",
    ")\n",
    "\n",
    "dataset.as_yolo(\n",
    "    annotations_directory_path=LABELS_OUTPUT_DIR,\n",
    "    min_image_area_percentage=0.01,\n",
    "    data_yaml_path=DATASET_DIR + \"/data.yaml\",\n",
    ")\n",
    "        \n",
    "\n",
    "\n",
    "yolo_model = YOLO('best.pt')\n",
    "yolo_model.to(device)\n",
    "results = yolo_model.train(data='/data.yaml', epochs=10, batch=8, imgsz=640, name=\"\", project=\"\")\n",
    "metrics = yolo_model.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.box.map  # map50-95(B)\n",
    "metrics.box.map50  # map50(B)\n",
    "metrics.box.map75  # map75(B)\n",
    "metrics.box.maps  # a list contains map50-95(B) of each category\n",
    "\n",
    "result = yolo_model.predict(source='/images/test', save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f81ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Behavior\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from groundingdino.util.inference import Model\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import supervision as sv\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Paths to models and images\n",
    "GROUNDING_DINO_CONFIG = \"groundingdino/config/GroundingDINO_SwinB_cfg.py\"  #can use SwinB and SwinT\n",
    "GROUNDING_DINO_CHECKPOINT = \"weights/groundingdino_swinb_cogcoor.pth\"\n",
    "\n",
    "DATASET_NAME = \"\"\n",
    "\n",
    "DATASET_DIR = f\"datasets/{DATASET_NAME}\"\n",
    "IMAGE_INPUT = f\"datasets/{DATASET_NAME}/images/val\"\n",
    "LABELS_OUTPUT_DIR = f\"datasets/{DATASET_NAME}/labels/val2\"\n",
    "ANNOTATED_IMG_OUTPUT = f\"datasets/{DATASET_NAME}/out_val\"\n",
    "YOLO_TEST_PATH = f\"datasets/{DATASET_NAME}/images/test/\"\n",
    "\n",
    "# Set the device for running models (MPS for MacBook, CUDA for GPU, CPU otherwise)\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "\n",
    "# Initialize Grounding DINO\n",
    "grounding_dino_model = Model(GROUNDING_DINO_CONFIG, GROUNDING_DINO_CHECKPOINT, device)\n",
    "\n",
    "# Define the classes or queries for Grounding DINO (your behavior classes)\n",
    "queries = [\n",
    "    \"\", \"\", \"\", \"\", \"\", \n",
    "    \"\", \"\", \"\", \"\", \"\", \"\"\n",
    "]\n",
    "\n",
    "# Load your pre-trained YOLO model\n",
    "yolo_model = YOLO('best.pt')  # Replace with the path to your best YOLO model\n",
    "yolo_model.to(device)\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(LABELS_OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(ANNOTATED_IMG_OUTPUT, exist_ok=True)\n",
    "\n",
    "# Box and label annotators\n",
    "box_annotator = sv.BoxAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
    "label_annotator = sv.LabelAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
    "\n",
    "# Function to filter detections by area\n",
    "def filter_detection_by_area(detections: sv.Detections):\n",
    "    mean_h = np.mean([y2 - y1 for _, y1, _, y2 in detections.xyxy])\n",
    "    mean_w = np.mean([x2 - x1 for x1, _, x2, _ in detections.xyxy])\n",
    "\n",
    "    std_h = np.std([y2 - y1 for _, y1, _, y2 in detections.xyxy])\n",
    "    std_w = np.std([x2 - x1 for x1, _, x2, _ in detections.xyxy])\n",
    "\n",
    "    area_indices = []\n",
    "    for _xyxy, _, _, _, _, _ in detections:\n",
    "        x1, y1, x2, y2 = _xyxy\n",
    "        val = False if (x2 - x1 >= mean_w + std_w) or (y2 - y1 > mean_h + std_h) else True\n",
    "        area_indices.append(val)\n",
    "    return detections[area_indices]\n",
    "\n",
    "# Function to convert bounding box to YOLO format\n",
    "def convert_to_yolo_format(detection, image_shape):\n",
    "    x1, y1, x2, y2 = detection.xyxy\n",
    "    width, height = image_shape[1], image_shape[0]\n",
    "\n",
    "    # Normalize coordinates by image dimensions\n",
    "    x_center = (x1 + x2) / 2 / width\n",
    "    y_center = (y1 + y2) / 2 / height\n",
    "    w = (x2 - x1) / width\n",
    "    h = (y2 - y1) / height\n",
    "\n",
    "    return [0, x_center, y_center, w, h]  # 0 corresponds to the first class (e.g., Feeding)\n",
    "\n",
    "# Function to save YOLO formatted labels\n",
    "def save_yolo_labels(image_name, detections, labels_output_dir):\n",
    "    label_file = os.path.join(labels_output_dir, image_name.replace('.jpg', '.txt'))\n",
    "    \n",
    "    with open(label_file, 'w') as f:\n",
    "        for detection in detections:\n",
    "            yolo_format = convert_to_yolo_format(detection, images_map[image_name].shape)\n",
    "            f.write(\" \".join(map(str, yolo_format)) + \"\\n\")\n",
    "\n",
    "# Ensure output directory exists for labels and annotated images\n",
    "os.makedirs(LABELS_OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(ANNOTATED_IMG_OUTPUT, exist_ok=True)\n",
    "\n",
    "# Load and process images from the dataset\n",
    "images_map = {}\n",
    "detections_map = {}\n",
    "progress_bar = tqdm(os.listdir(IMAGE_INPUT), desc=\"Labeling images\")\n",
    "for image_name in progress_bar:\n",
    "    progress_bar.set_description(desc=f\"Labeling {image_name}\", refresh=True)\n",
    "    image_path = os.path.join(IMAGE_INPUT, image_name)\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    images_map[image_name] = image.copy()\n",
    "\n",
    "    # Grounding DINO inference\n",
    "    detections = grounding_dino_model.predict_with_classes(\n",
    "        image=image,\n",
    "        classes=queries,  # Use the full set of behavior queries\n",
    "        box_threshold=0.13,\n",
    "        text_threshold=0.2,\n",
    "    )\n",
    "    detections = detections.with_nms(threshold=1)  # Confidence interval to remove multiple boxes\n",
    "    detections.class_id = np.zeros(len(detections.xyxy))  # Set the class_id to 0 for behavior classes\n",
    "    detections = filter_detection_by_area(detections)\n",
    "    detections_map[image_name] = detections\n",
    "\n",
    "    # Annotate with labels\n",
    "    labels = [f\"{queries[int(class_id)]} {confidence:0.2f}\" for _, _, confidence, class_id, _, _ in detections]\n",
    "    annotated_frame = cv2.cvtColor(image.copy(), cv2.COLOR_RGB2BGR)\n",
    "    annotated_image = box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "    annotated_image = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)\n",
    "    cv2.imwrite(os.path.join(ANNOTATED_IMG_OUTPUT, image_name), annotated_image)\n",
    "\n",
    "# Process test images with YOLO model and save the labels in YOLO format\n",
    "test_images = os.listdir(YOLO_TEST_PATH)\n",
    "for image_name in test_images:\n",
    "    image_path = os.path.join(YOLO_TEST_PATH, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Run YOLO prediction\n",
    "    results = yolo_model(image)\n",
    "\n",
    "    # Extract detections (bounding boxes and scores)\n",
    "    detections = results[0].boxes.xyxy  # Get the bounding box coordinates\n",
    "    scores = results[0].boxes.conf  # Get the confidence scores\n",
    "    class_ids = results[0].boxes.cls  # Get the class IDs\n",
    "\n",
    "    # Filter detections based on a confidence threshold\n",
    "    detections = [detection for detection, score in zip(detections, scores) if score > 0.5]\n",
    "\n",
    "    # Save the YOLO formatted labels for this image\n",
    "    save_yolo_labels(image_name, detections, LABELS_OUTPUT_DIR)\n",
    "\n",
    "    # Optionally, annotate and save the image with bounding boxes\n",
    "    annotated_image = image.copy()\n",
    "    for detection in detections:\n",
    "        x1, y1, x2, y2 = detection\n",
    "        cv2.rectangle(annotated_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "\n",
    "    # Save the annotated image\n",
    "    annotated_image_path = os.path.join(ANNOTATED_IMG_OUTPUT, image_name)\n",
    "    cv2.imwrite(annotated_image_path, annotated_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
